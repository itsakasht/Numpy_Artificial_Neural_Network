{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for MNIST fashion dataset\n",
    "Uses only basic libraries\n",
    "- Numpy for linear algebra\n",
    "- Pandas for storing results\n",
    "- Matplotlib to plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "import importlib\n",
    "import layers as ly\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data formating\n",
    "Need each datapoint ie. each image as a vector. Hence all data points are column vectors of 784 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000) (10, 60000) (784, 10000) (10, 10000)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = np.reshape(x_train, (-1, 784)).T / 255 # features x samples\n",
    "x_test = np.reshape(x_test, (-1, 784)).T / 255 # features x samples\n",
    "\n",
    "y_train = ly.one_hot_encode(y_train) # one-hot encode labels x samples\n",
    "y_test = ly.one_hot_encode(y_test) # one-hot encode labels x samples\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "print(x_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28, 60000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 6, figsize=(15, 6))\n",
    "plt.set_cmap('gray')\n",
    "print(np.reshape(x_train, (28, 28, -1)).shape)\n",
    "for i in range(6):\n",
    "    ax[i].imshow(np.reshape(x_train, (28, 28, -1))[:, :, i])\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.5654, Accuracy: 0.8290\n",
      "Epoch 1, Loss: 0.2322, Accuracy: 0.9310\n",
      "Epoch 2, Loss: 0.1775, Accuracy: 0.9478\n",
      "Epoch 3, Loss: 0.1499, Accuracy: 0.9560\n",
      "Epoch 4, Loss: 0.1297, Accuracy: 0.9616\n",
      "Epoch 5, Loss: 0.1167, Accuracy: 0.9655\n",
      "Epoch 6, Loss: 0.1056, Accuracy: 0.9685\n",
      "Epoch 7, Loss: 0.0970, Accuracy: 0.9707\n",
      "Epoch 8, Loss: 0.0897, Accuracy: 0.9726\n",
      "Epoch 9, Loss: 0.0830, Accuracy: 0.9749\n",
      "Epoch 10, Loss: 0.0790, Accuracy: 0.9758\n",
      "Epoch 11, Loss: 0.0728, Accuracy: 0.9772\n",
      "Epoch 12, Loss: 0.0688, Accuracy: 0.9789\n",
      "Epoch 13, Loss: 0.0645, Accuracy: 0.9796\n",
      "Epoch 14, Loss: 0.0621, Accuracy: 0.9803\n",
      "Epoch 15, Loss: 0.0582, Accuracy: 0.9819\n",
      "Epoch 16, Loss: 0.0553, Accuracy: 0.9829\n",
      "Epoch 17, Loss: 0.0520, Accuracy: 0.9839\n",
      "Epoch 18, Loss: 0.0493, Accuracy: 0.9848\n",
      "Epoch 19, Loss: 0.0473, Accuracy: 0.9855\n",
      "Epoch 20, Loss: 0.0450, Accuracy: 0.9860\n",
      "Epoch 21, Loss: 0.0426, Accuracy: 0.9866\n",
      "Epoch 22, Loss: 0.0416, Accuracy: 0.9867\n",
      "Epoch 23, Loss: 0.0383, Accuracy: 0.9883\n",
      "Epoch 24, Loss: 0.0379, Accuracy: 0.9881\n",
      "Epoch 25, Loss: 0.0349, Accuracy: 0.9892\n",
      "Epoch 26, Loss: 0.0349, Accuracy: 0.9890\n",
      "Epoch 27, Loss: 0.0329, Accuracy: 0.9893\n",
      "Epoch 28, Loss: 0.0318, Accuracy: 0.9902\n",
      "Epoch 29, Loss: 0.0293, Accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ly)\n",
    "\n",
    "network = [ly.LayerDense(784, 32),\n",
    "           ly.ActivationReLU(),\n",
    "           ly.LayerDense(32, 32),\n",
    "           ly.ActivationReLU(),\n",
    "           ly.LayerDense(32, 10),\n",
    "           ly.ActivationSoftmaxLossCrossEntropy()\n",
    "]\n",
    "\n",
    "epochs = 30\n",
    "learning_rate = 0.01\n",
    "batch_size = 64\n",
    "total_samples = x_train.shape[1]\n",
    "\n",
    "optimizer = ly.NestrovGradientDescent(learning_rate, momentum=0.9)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    indices = np.random.permutation(total_samples)\n",
    "    x_shuffled = x_train[:, indices]\n",
    "    y_shuffled = y_train[:, indices]\n",
    "\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for start in range(0, total_samples, batch_size):\n",
    "        end = start + batch_size\n",
    "        x_batch = x_shuffled[:, start:end]\n",
    "        y_batch = y_shuffled[:, start:end]\n",
    "\n",
    "        # Forward pass\n",
    "        inputs = x_batch\n",
    "        for layer in network:\n",
    "            inputs = layer.forward(inputs)\n",
    "        predictions = inputs\n",
    "\n",
    "        # Loss\n",
    "        loss = network[-1].loss(y_batch)\n",
    "        epoch_loss += loss * x_batch.shape[1]  # Weighted sum\n",
    "\n",
    "        # Accuracy\n",
    "        y_pred = np.argmax(predictions, axis=0)\n",
    "        y_label = np.argmax(y_batch, axis=0)\n",
    "        correct += np.sum(y_pred == y_label)\n",
    "\n",
    "        # Backward pass\n",
    "        d_loss = network[-1].backward(y_batch)\n",
    "        for layer in reversed(network[:-1]):\n",
    "            d_loss = layer.backward(d_loss)\n",
    "\n",
    "        # Update weights\n",
    "        for layer in network:\n",
    "            if isinstance(layer, ly.LayerDense):\n",
    "                dw, db = layer.gradient()\n",
    "                optimizer.update(layer)\n",
    "\n",
    "    avg_loss = epoch_loss / total_samples\n",
    "    accuracy = correct / total_samples\n",
    "    print(f'Epoch {epoch}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6196, Accuracy: 0.8058\n",
      "Epoch 5, Loss: 0.1315, Accuracy: 0.9640\n",
      "Epoch 10, Loss: 0.0912, Accuracy: 0.9742\n",
      "Epoch 15, Loss: 0.0745, Accuracy: 0.9789\n",
      "Epoch 20, Loss: 0.0642, Accuracy: 0.9819\n",
      "Epoch 25, Loss: 0.0558, Accuracy: 0.9835\n",
      "Epoch 30, Loss: 0.0506, Accuracy: 0.9851\n",
      "Epoch 35, Loss: 0.0467, Accuracy: 0.9865\n",
      "Epoch 40, Loss: 0.0452, Accuracy: 0.9866\n",
      "Epoch 45, Loss: 0.0390, Accuracy: 0.9884\n",
      "Epoch 50, Loss: 0.0366, Accuracy: 0.9892\n",
      "Epoch 55, Loss: 0.0331, Accuracy: 0.9899\n",
      "Epoch 60, Loss: 0.0334, Accuracy: 0.9903\n",
      "Epoch 65, Loss: 0.0294, Accuracy: 0.9913\n",
      "Epoch 70, Loss: 0.0308, Accuracy: 0.9909\n",
      "Epoch 75, Loss: 0.0283, Accuracy: 0.9916\n",
      "Epoch 80, Loss: 0.0300, Accuracy: 0.9904\n",
      "Epoch 85, Loss: 0.0294, Accuracy: 0.9913\n",
      "Epoch 90, Loss: 0.0262, Accuracy: 0.9924\n",
      "Epoch 95, Loss: 0.0271, Accuracy: 0.9922\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(ly) \n",
    "\n",
    "network = [\n",
    "    ly.LayerDense(784, 128),\n",
    "    ly.ActivationReLU(),\n",
    "    ly.Dropout(rate=0.2),          # Dropout after first hidden layer\n",
    "    ly.LayerDense(128, 64),\n",
    "    ly.ActivationReLU(),\n",
    "    ly.Dropout(rate=0.4),          # Dropout after second hidden layer\n",
    "    ly.LayerDense(64, 32),\n",
    "    ly.ActivationReLU(),\n",
    "    ly.Dropout(rate=0.2),          # Dropout after third hidden layer\n",
    "    ly.LayerDense(32, 10),\n",
    "    ly.ActivationSoftmaxLossCrossEntropy()\n",
    "]\n",
    "\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "batch_size = 128\n",
    "total_samples = x_train.shape[1]\n",
    "\n",
    "optimizer = ly.AdamOptimizer(learning_rate=0.001)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    indices = np.random.permutation(total_samples)\n",
    "    x_shuffled = x_train[:, indices]\n",
    "    y_shuffled = y_train[:, indices]\n",
    "\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for start in range(0, total_samples, batch_size):\n",
    "        end = start + batch_size\n",
    "        x_batch = x_shuffled[:, start:end]\n",
    "        y_batch = y_shuffled[:, start:end]\n",
    "\n",
    "        # Forward pass\n",
    "        inputs = x_batch\n",
    "        for layer in network:\n",
    "            # Dropout is only active during training\n",
    "            if isinstance(layer, ly.Dropout):\n",
    "                inputs = layer.forward(inputs, training=True)\n",
    "            else:\n",
    "                inputs = layer.forward(inputs)\n",
    "        predictions = inputs\n",
    "\n",
    "        # Loss\n",
    "        loss = network[-1].loss(y_batch)\n",
    "        epoch_loss += loss * x_batch.shape[1]  # Weighted sum\n",
    "\n",
    "        # Accuracy\n",
    "        y_pred = np.argmax(predictions, axis=0)\n",
    "        y_label = np.argmax(y_batch, axis=0)\n",
    "        correct += np.sum(y_pred == y_label)\n",
    "\n",
    "        # Backward pass\n",
    "        d_loss = network[-1].backward(y_batch)\n",
    "        for layer in reversed(network[:-1]):\n",
    "            d_loss = layer.backward(d_loss)\n",
    "\n",
    "        # Update weights\n",
    "        for layer in network:\n",
    "            if isinstance(layer, ly.LayerDense):\n",
    "                dw, db = layer.gradient()\n",
    "                optimizer.update(layer)\n",
    "\n",
    "    avg_loss = epoch_loss / total_samples\n",
    "    accuracy = correct / total_samples\n",
    "    if epoch%5 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.16%\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "inputs = x_test\n",
    "for layer in network:\n",
    "    inputs = layer.forward(inputs)\n",
    "predictions = inputs\n",
    "y_pred = np.argmax(predictions, axis=0)\n",
    "y_label = np.argmax(y_test, axis=0)\n",
    "correct = np.sum(y_pred == y_label)\n",
    "accuracy = correct / y_test.shape[1]\n",
    "print(f'Test Accuracy: {100*accuracy:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
